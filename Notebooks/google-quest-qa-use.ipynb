{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Concatenate, BatchNormalization, Activation\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls ../input\n",
    "\n",
    "DATA_DIR = '../kaggle/input/google-quest-challenge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qa_id'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")\n",
    "targets = list(submission.columns)\n",
    "targets.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (6079, 41)\n",
      "test (476, 11)\n",
      "sample_submission (476, 31)\n"
     ]
    }
   ],
   "source": [
    "print('train', train.shape)\n",
    "print('test', test.shape)\n",
    "print('sample_submission', submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_columns = list(train.columns)\n",
    "question_answer_cols = all_train_columns[:11]\n",
    "question_target_cols = all_train_columns[11:32]\n",
    "answer_target_cols  = all_train_columns[32:41]\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-4\n",
    "EMBEDDDING_SIZE = 512\n",
    "N_CLASS = len(target_cols)\n",
    "ES_PATIENCE = 3\n",
    "RLROP_PATIENCE = 2\n",
    "DECAY_DROP = 0.3\n",
    "N_FOLD = 5\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "MODEL_PATH = '../working/model_%d.h5'\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_embed = hub.load(module_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def USEEmbedding(x):\n",
    "    return use_embed(tf.squeeze(tf.cast(x, tf.string)))\n",
    "\n",
    "def swish(x):\n",
    "    return K.sigmoid(x) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():    \n",
    "    input_title = Input(shape=(1,), dtype=tf.string, name='input_title')\n",
    "    embedding_title = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_title)\n",
    "\n",
    "    input_body = Input(shape=(1,), dtype=tf.string, name='input_body')\n",
    "    embedding_body = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_body)\n",
    "    \n",
    "    input_answer = Input(shape=(1,), dtype=tf.string, name='input_answer')\n",
    "    embedding_answer = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_answer)\n",
    "\n",
    "    x = Concatenate()([embedding_title, embedding_body, embedding_answer])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation=swish)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(N_CLASS, activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=[input_title, input_body, input_answer], outputs=[output])\n",
    "\n",
    "    optimizer = optimizers.Adam(LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_fn().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = ['question_title', 'question_body', 'answer']\n",
    "x_train = train[x_labels]\n",
    "y_train = train[targets]\n",
    "\n",
    "x_train = [x_train[col] for col in x_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What am I losing when using extension tubes instead of a macro lens?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df, cols: list):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace(\"?\",\".\"))\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace(\"!\",\".\"))\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace(\"\\n\",\" \"))\n",
    "        df[col] = df[col].apply(lambda x: re.sub('[0-9]+', '0', x))\n",
    "    return df\n",
    "\n",
    "train = pre_processing(train, x_labels)\n",
    "\n",
    "#display(train.head())\n",
    "\n",
    "test = pre_processing(test, x_labels)\n",
    "#display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What am I losing when using extension tubes instead of a macro lens?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After playing around with macro photography on-the-cheap (read: reversed lens, rev. lens mounted on a straight lens, passive extension tubes), I would like to get further with this. The problems with the techniques I used is that focus is manual and aperture control is problematic at best. This limited my setup to still subjects (read: dead insects) Now, as spring is approaching, I want to be able to shoot live insects. I believe that for this, autofocus and settable aperture will be of great help.\\n\\nSo, one obvious but expensive option is a macro lens (say, EF 100mm Macro) However, I am not really interested in yet another prime lens. An alternative is the electrical extension tubes.\\n\\nExcept for maximum focusing distance, what am I losing when using tubes (coupled with a fine lens, say EF70-200/2.8) instead of a macro lens?\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just got extension tubes, so here's the skinny.\\n\\n\\n  ...what am I losing when using tubes...?\\n\\n\\nA very considerable amount of light!  Increasing that distance from the end of the lens to the sensor can cut your light several stops.  Combined with the fact that you'll usually shoot stopped down - expect to need to increase your ISO considerably.\\n\\nThe fact the macro's are usually considered very very sharp, although I believe that 70-200mm 2.8 is supposed to be quite sharp.\\n\\nThe ultra low distortion typical of many macros.\\n\\nI wouldn't worry too much about the bokeh since the DOF will still be quite limited.\\n\\nCoupled on my 50mm, a full 60mm'ish extension tube results in a DOF of about a couple inches in front of the lens.  On my 70-300, its probably around 2-3 feet in front of the lens to about a foot in front of the lens.\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/20\n",
      "4863/4863 [==============================] - 9s 2ms/sample - loss: 0.7819 - val_loss: 0.5852\n",
      "Epoch 2/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.5908 - val_loss: 0.4424\n",
      "Epoch 3/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.4618 - val_loss: 0.3972\n",
      "Epoch 4/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4242 - val_loss: 0.3860\n",
      "Epoch 5/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.4096 - val_loss: 0.3829\n",
      "Epoch 6/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.4020 - val_loss: 0.3813\n",
      "Epoch 7/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3970 - val_loss: 0.3799\n",
      "Epoch 8/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3918 - val_loss: 0.3791\n",
      "Epoch 9/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3883 - val_loss: 0.3786\n",
      "Epoch 10/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3843 - val_loss: 0.3781\n",
      "Epoch 11/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3824 - val_loss: 0.3776\n",
      "Epoch 12/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3798 - val_loss: 0.3772\n",
      "Epoch 13/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3779 - val_loss: 0.3769\n",
      "Epoch 14/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3768 - val_loss: 0.3766\n",
      "Epoch 15/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3750 - val_loss: 0.3764\n",
      "Epoch 16/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3743 - val_loss: 0.3765\n",
      "Epoch 17/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3722 - val_loss: 0.3760\n",
      "Epoch 18/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3716 - val_loss: 0.3759\n",
      "Epoch 19/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3697 - val_loss: 0.3756\n",
      "Epoch 20/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3700 - val_loss: 0.3758\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/20\n",
      "4863/4863 [==============================] - 7s 2ms/sample - loss: 0.7787 - val_loss: 0.5833\n",
      "Epoch 2/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.5873 - val_loss: 0.4408\n",
      "Epoch 3/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4599 - val_loss: 0.3967\n",
      "Epoch 4/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4223 - val_loss: 0.3856\n",
      "Epoch 5/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.4108 - val_loss: 0.3823\n",
      "Epoch 6/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.4015 - val_loss: 0.3803\n",
      "Epoch 7/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3960 - val_loss: 0.3794\n",
      "Epoch 8/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3923 - val_loss: 0.3787\n",
      "Epoch 9/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3871 - val_loss: 0.3777\n",
      "Epoch 10/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3845 - val_loss: 0.3776\n",
      "Epoch 11/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3821 - val_loss: 0.3772\n",
      "Epoch 12/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3791 - val_loss: 0.3764\n",
      "Epoch 13/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3780 - val_loss: 0.3762\n",
      "Epoch 14/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3759 - val_loss: 0.3763\n",
      "Epoch 15/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3755 - val_loss: 0.3759\n",
      "Epoch 16/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3735 - val_loss: 0.3759\n",
      "Epoch 17/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3726 - val_loss: 0.3758\n",
      "Epoch 18/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3714 - val_loss: 0.3754\n",
      "Epoch 19/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3706 - val_loss: 0.3758\n",
      "Epoch 20/20\n",
      "4832/4863 [============================>.] - ETA: 0s - loss: 0.3701\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3700 - val_loss: 0.3755\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/20\n",
      "4863/4863 [==============================] - 8s 2ms/sample - loss: 0.7801 - val_loss: 0.5718\n",
      "Epoch 2/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.5902 - val_loss: 0.4283\n",
      "Epoch 3/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4606 - val_loss: 0.3973\n",
      "Epoch 4/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4235 - val_loss: 0.3885\n",
      "Epoch 5/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4095 - val_loss: 0.3843\n",
      "Epoch 6/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4024 - val_loss: 0.3824\n",
      "Epoch 7/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3955 - val_loss: 0.3809\n",
      "Epoch 8/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3924 - val_loss: 0.3800\n",
      "Epoch 9/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3873 - val_loss: 0.3792\n",
      "Epoch 10/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3843 - val_loss: 0.3785\n",
      "Epoch 11/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3825 - val_loss: 0.3781\n",
      "Epoch 12/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3797 - val_loss: 0.3777\n",
      "Epoch 13/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3782 - val_loss: 0.3772\n",
      "Epoch 14/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3765 - val_loss: 0.3772\n",
      "Epoch 15/20\n",
      "4832/4863 [============================>.] - ETA: 0s - loss: 0.3749\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3749 - val_loss: 0.3773\n",
      "Epoch 16/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3727 - val_loss: 0.3769\n",
      "Epoch 17/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3725 - val_loss: 0.3767\n",
      "Epoch 18/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3715 - val_loss: 0.3766\n",
      "Epoch 19/20\n",
      "4800/4863 [============================>.] - ETA: 0s - loss: 0.3708\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3707 - val_loss: 0.3767\n",
      "Epoch 20/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3703 - val_loss: 0.3766\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/20\n",
      "4863/4863 [==============================] - 8s 2ms/sample - loss: 0.7800 - val_loss: 0.5788\n",
      "Epoch 2/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.5884 - val_loss: 0.4347\n",
      "Epoch 3/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4613 - val_loss: 0.3971\n",
      "Epoch 4/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4239 - val_loss: 0.3872\n",
      "Epoch 5/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4113 - val_loss: 0.3830\n",
      "Epoch 6/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.4017 - val_loss: 0.3812\n",
      "Epoch 7/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3954 - val_loss: 0.3799\n",
      "Epoch 8/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3912 - val_loss: 0.3791\n",
      "Epoch 9/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3885 - val_loss: 0.3784\n",
      "Epoch 10/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3846 - val_loss: 0.3780\n",
      "Epoch 11/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3821 - val_loss: 0.3778\n",
      "Epoch 12/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3800 - val_loss: 0.3771\n",
      "Epoch 13/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3790 - val_loss: 0.3766\n",
      "Epoch 14/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3765 - val_loss: 0.3766\n",
      "Epoch 15/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3748 - val_loss: 0.3764\n",
      "Epoch 16/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3734 - val_loss: 0.3762\n",
      "Epoch 17/20\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3722 - val_loss: 0.3758\n",
      "Epoch 18/20\n",
      "4863/4863 [==============================] - 7s 1ms/sample - loss: 0.3710 - val_loss: 0.3759\n",
      "Epoch 19/20\n",
      "4832/4863 [============================>.] - ETA: 0s - loss: 0.3707\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "4863/4863 [==============================] - 6s 1ms/sample - loss: 0.3709 - val_loss: 0.3759\n",
      "Epoch 20/20\n",
      "1792/4863 [==========>...................] - ETA: 3s - loss: 0.3673"
     ]
    }
   ],
   "source": [
    "callback_list = [es, rlrop]\n",
    "\n",
    "for i in range(N_FOLD):\n",
    "    model = model_fn()\n",
    "    history = model.fit(x_train, y_train, validation_split=0.2, shuffle=True, batch_size=BATCH_SIZE, callbacks=callback_list, epochs=EPOCHS, verbose=1)\n",
    "    #model.save_weights(MODEL_PATH % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = ['question_title', 'question_body', 'answer']\n",
    "x_test = test[x_labels]\n",
    "x_test = [x_test[col] for col in x_labels]\n",
    "y_tests = np.zeros((N_FOLD, len(test), len(target_cols)))\n",
    "\n",
    "for i in range(N_FOLD):\n",
    "    model = model_fn()\n",
    "    model.load_weights(MODEL_PATH % i)\n",
    "    y_tests[i] = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "submission[target_cols] = np.average(y_tests, axis = 0)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
